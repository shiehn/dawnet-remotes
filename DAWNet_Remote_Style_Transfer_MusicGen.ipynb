{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiehn/dawnet-remotes/blob/main/DAWNet_Remote_Style_Transfer_MusicGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU CHECK"
      ],
      "metadata": {
        "id": "McdVeV4qPc6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "rKRWzmXOPYB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALL MUSIC_GEN"
      ],
      "metadata": {
        "id": "HiMMosp-Pt2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install -U git+https://github.com/facebookresearch/audiocraft#egg=audiocraft\n",
        "# !python3 -m pip install -U audiocraft\n",
        "\n",
        "import torchaudio\n",
        "from audiocraft.models import MusicGen\n",
        "from audiocraft.data.audio import audio_write\n",
        "\n",
        "model = MusicGen.get_pretrained('facebook/musicgen-melody')\n",
        "\n"
      ],
      "metadata": {
        "id": "ku0ui5lKwpF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "ffmpeg_installed = !command -v ffmpeg\n",
        "if not ffmpeg_installed:\n",
        "    !apt-get install ffmpeg\n",
        "\n",
        "!pip install dawnet-client\n",
        "\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "import uuid\n",
        "import os\n",
        "import dawnet_client.core as dawnet\n",
        "from dawnet_client import DAWNetFilePath, utils\n",
        "\n",
        "placeholder_txt = \"Enter the token generated by the DAWNet plugin\"\n",
        "DAWNET_TOKEN = \"5941402a-38d3-4064-bf23-6e0b44cafe0b\" #@param {type:\"string\"}\n",
        "dawnet_token = DAWNET_TOKEN\n",
        "\n",
        "if dawnet_token is None or dawnet_token == \"\" or dawnet_token == placeholder_txt:\n",
        "  print(\"ERROR: The token provided is not valid.\")\n",
        "  exit()\n",
        "\n",
        "async def dawnet_func(description:str=\"childrens choir\", audio_input:DAWNetFilePath=None):\n",
        "    try:\n",
        "        print(\"FILEPATH: \" + str(audio_input))\n",
        "\n",
        "        audio_length=utils.get_audio_length(audio_input)\n",
        "\n",
        "        print(\"audio_length: \" + str(audio_length))\n",
        "\n",
        "        bpm_str = str(round(dawnet.get_daw_bpm()))\n",
        "        print(\"bpm: \" + bpm_str\n",
        "\n",
        "        num_samples=1 # REPLACE ME\n",
        "        output_audio_name = \"output.wav\"\n",
        "\n",
        "        model.set_generation_params(duration=audio_length)\n",
        "        descriptions = [description + \" at \" + bpm_str + \" bpm\"]\n",
        "        melody, sr = torchaudio.load(audio_input)\n",
        "\n",
        "        # generates using the melody from the given audio and the provided descriptions.\n",
        "        wav = model.generate_with_chroma(descriptions, melody[None].expand(num_samples, -1, -1), sr)\n",
        "\n",
        "        print('generations complete')\n",
        "\n",
        "        for idx, one_wav in enumerate(wav):\n",
        "          # Will save under {idx}.wav, with loudness normalization at -14 db LUFS.\n",
        "          #audio_write(f'{idx}', one_wav.cpu(), model.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "\n",
        "          # Move the tensor to CPU, convert to numpy array, reshape and ensure the data type is float32\n",
        "          generated_audio = one_wav.cpu().numpy().astype('float32')\n",
        "          generated_audio = generated_audio.squeeze()  # Remove extra dimensions\n",
        "\n",
        "          output_audio_name = f\"{str(uuid.uuid4())}.wav\"\n",
        "          sf.write(output_audio_name, generated_audio, 32000, subtype='PCM_16')  # Save as WAV file\n",
        "\n",
        "          print(\"Adding file to output: \" + str(output_audio_name))\n",
        "\n",
        "          # after executing your custom code you send data back to the plugin like so ..\n",
        "          await dawnet.output().add_file(output_audio_name)\n",
        "\n",
        "\n",
        "        await dawnet.output().add_message(\"Returning the input file\")\n",
        "        await dawnet.output().send()\n",
        "\n",
        "        print(\"output sent.\")\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in arbitrary_method: {e}\")\n",
        "        return f\"Method encountered an error: {e}\"\n",
        "\n",
        "\n",
        "dawnet.set_token(token=dawnet_token)\n",
        "dawnet.set_name(\"MusicGen Style Transfer\")\n",
        "dawnet.set_description(\"Provide a text description, number of samples, and sample lenth in seconds\")\n",
        "dawnet.register_method(dawnet_func)\n",
        "\n",
        "dawnet.set_input_target_format('wav')\n",
        "dawnet.set_input_target_channels(2)\n",
        "dawnet.set_input_target_sample_rate(32000)\n",
        "dawnet.set_input_target_bit_depth(16)\n",
        "\n",
        "dawnet.set_output_target_format('wav')\n",
        "dawnet.set_output_target_channels(2)\n",
        "dawnet.set_output_target_sample_rate(44100)\n",
        "dawnet.set_output_target_bit_depth(16)\n",
        "\n",
        "dawnet.connect_to_server()"
      ],
      "metadata": {
        "id": "32g-tH7IZz5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See our repo https://github.com/facebookresearch/audiocraft for more details on how to use this model!\n",
        "\n",
        "See also [MusicGen Gradio Demo](https://colab.research.google.com/drive/1-Xe9NCdIs2sCUbiSmwHXozK6AAhMm7_i?usp=sharing) for a Colab using the Gradio app instead!\n"
      ],
      "metadata": {
        "id": "yP3FfELNw6_k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMEhDDBWo-BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rojR90c5xFMY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}